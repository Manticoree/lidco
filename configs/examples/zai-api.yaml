# ─────────────────────────────────────────────────────────────────────────────
# LIDCO — Z.AI API Configuration (Pay-per-Token)
# ─────────────────────────────────────────────────────────────────────────────
#
# Конфигурация для Z.AI API с оплатой по токенам (без подписки).
# Используется стандартный API endpoint.
#
# Установка:
#   1. Зарегистрируйтесь на https://open.bigmodel.cn
#   2. Пополните баланс
#   3. Скопируйте API-ключ
#   4. Скопируйте этот файл:
#      cp configs/examples/zai-api.yaml ~/.lidco/llm_providers.yaml
#   5. Добавьте ключ в .env:
#      ZAI_API_KEY=your_key_here
#
# Цены (за 1M токенов):
#   GLM-4.7          — $0.60 / $2.20
#   GLM-4.7-FlashX   — $0.07 / $0.40
#   GLM-4.5-Air      — $0.20 / $1.10
#   GLM-4.7-Flash    — Бесплатно
#   GLM-4.5-Flash    — Бесплатно
#
# ─────────────────────────────────────────────────────────────────────────────


# ── Провайдеры ────────────────────────────────────────────────────────────────

providers:
  zai:
    api_base: "https://open.bigmodel.cn/api/paas/v4"
    api_key: "${ZAI_API_KEY}"
    models:
      - openai/glm-4.7
      - openai/glm-4.7-flashx
      - openai/glm-4.5-air
      - openai/glm-4.7-flash
      - openai/glm-4.5-flash


# ── Модели по ролям ───────────────────────────────────────────────────────────

role_models:
  default:
    model: "openai/glm-4.7"
    fallback: "openai/glm-4.7-flashx"
    temperature: 0.1

  # Бесплатная модель для роутинга
  routing:
    model: "openai/glm-4.7-flash"
    temperature: 0.0
    max_tokens: 50

  # Бесплатная модель для автодополнения
  completion:
    model: "openai/glm-4.5-flash"
    temperature: 0.0
    max_tokens: 256

  coder:
    model: "openai/glm-4.7"
    fallback: "openai/glm-4.7-flashx"
    temperature: 0.1
    max_tokens: 4096

  reviewer:
    model: "openai/glm-4.7"
    fallback: "openai/glm-4.7-flashx"
    temperature: 0.0

  planner:
    model: "openai/glm-4.7"
    fallback: "openai/glm-4.7-flashx"
    temperature: 0.1

  architect:
    model: "openai/glm-4.7"
    fallback: "openai/glm-4.7-flashx"
    temperature: 0.1

  debugger:
    model: "openai/glm-4.7"
    fallback: "openai/glm-4.7-flashx"
    temperature: 0.0

  refactor:
    model: "openai/glm-4.7"
    fallback: "openai/glm-4.7-flashx"
    temperature: 0.1

  tester:
    model: "openai/glm-4.7-flashx"
    fallback: "openai/glm-4.5-flash"
    temperature: 0.1

  docs:
    model: "openai/glm-4.7-flashx"
    fallback: "openai/glm-4.5-flash"
    temperature: 0.3
