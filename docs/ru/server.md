# HTTP-сервер

HTTP-сервер LIDCO предоставляет REST/SSE API на localhost для интеграции с IDE. Он использует ту же сессию, агентов и инструменты, что и CLI.

## Запуск сервера

```bash
# По умолчанию: localhost:8321
lidco serve

# Пользовательский порт
lidco serve --port 9000

# Привязка ко всем интерфейсам (для удалённого доступа — используйте с осторожностью)
lidco serve --host 0.0.0.0

# Указать директорию проекта
lidco serve --project-dir /path/to/project
```

## Переменные окружения

| Переменная | По умолчанию | Описание |
|------------|-------------|----------|
| `LIDCO_API_TOKEN` | _(пусто)_ | Bearer-токен для аутентификации. Если пусто — авторизация отключена (режим локальной разработки) |
| `LIDCO_ALLOWED_ORIGINS` | `http://localhost:*,http://127.0.0.1:*` | Разрешённые CORS-источники через запятую |
| `LIDCO_DEBUG` | `false` | Установите `1` или `true` для подробных сообщений об ошибках в ответах API |
| `LIDCO_DEFAULT_MODEL` | `gpt-4o-mini` | Переопределение модели по умолчанию |
| `LIDCO_LOG_LEVEL` | `INFO` | Уровень логирования |

## Аутентификация

По умолчанию (без установленного `LIDCO_API_TOKEN`) все запросы разрешены. Это нормально для локальной разработки.

Для включения аутентификации:

```bash
export LIDCO_API_TOKEN=my-secret-token
lidco serve
```

Затем включайте токен в запросы:

```bash
curl -H "Authorization: Bearer my-secret-token" \
     http://127.0.0.1:8321/api/status
```

Эндпоинт `/health` всегда доступен без аутентификации.

## Проверка работоспособности

```bash
curl http://127.0.0.1:8321/health
# {"status": "ok"}
```

Используйте для мониторинга, проб балансировщика нагрузки или проверки подключения IDE.

## Архитектура

```
┌──────────────┐
│  IDE / curl   │
└──────┬───────┘
       │ HTTP (localhost:8321)
┌──────▼───────┐
│   FastAPI     │  ← CORS, Auth, Logging middleware
├──────────────┤
│   Session     │  ← Как в CLI: LLM + Tools + Agents
├──────────────┤
│  Orchestrator │  ← Маршрутизация сообщений к агентам
├──────────────┤
│   Agents      │  ← coder, reviewer, planner, debugger, ...
├──────────────┤
│   LLM Layer   │  ← litellm (OpenAI, Anthropic, Ollama, ...)
└──────────────┘
```

Сервер создаёт единственный экземпляр `Session` при первом запросе (ленивая инициализация). Все эндпоинты разделяют эту сессию, что означает сохранение истории диалога между запросами в рамках одного процесса сервера.

## SSE-стриминг

Эндпоинт `/api/chat/stream` использует Server-Sent Events для потоковой передачи ответов в реальном времени.

Типы событий:

| Событие | Данные | Описание |
|---------|--------|----------|
| `start` | `{"agent": "coder"}` | Поток начат, агент выбран |
| `token` | `{"text": "часть..."}` | Часть текста ответа |
| `tool_call` | `{"tool": "file_read", "args": {...}}` | Агент вызвал инструмент |
| `done` | `{"agent": "coder", "model_used": "gpt-4o", "iterations": 2}` | Поток завершён |
| `error` | `{"message": "..."}` | Произошла ошибка |

Пример с curl:

```bash
curl -N -X POST http://127.0.0.1:8321/api/chat/stream \
     -H "Content-Type: application/json" \
     -d '{"message": "объясни что делает этот проект"}'
```

## Остановка сервера

Нажмите **Ctrl+C** в терминале, где запущен `lidco serve`.
