# Быстрый старт

## Требования

- Python 3.12+
- API-ключ хотя бы одного LLM-провайдера (OpenAI, Anthropic, Groq или локальный Ollama)

## Установка

```bash
# Клонировать репозиторий
git clone https://github.com/lidco/lidco.git
cd lidco

# Установить в режиме разработки
pip install -e ".[dev]"

# Скопировать шаблон переменных окружения
cp .env.example .env
```

## Настройка API-ключей

Отредактируйте `.env` и добавьте ключи:

```env
# Выберите одного или нескольких провайдеров
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
GROQ_API_KEY=gsk_...

# Или используйте Ollama (ключ не нужен)
# OLLAMA_BASE_URL=http://localhost:11434

# Модель по умолчанию
LIDCO_DEFAULT_MODEL=gpt-4o-mini
```

## Первый запуск (режим CLI)

```bash
lidco
```

Вы увидите баннер LIDCO и приглашение ввода:

```
 ██╗     ██╗██████╗  ██████╗ ██████╗
 ██║     ██║██╔══██╗██╔════╝██╔═══██╗
 ██║     ██║██║  ██║██║     ██║   ██║
 ██║     ██║██║  ██║██║     ██║   ██║
 ███████╗██║██████╔╝╚██████╗╚██████╔╝
 ╚══════╝╚═╝╚═════╝  ╚═════╝ ╚═════╝

You >
```

### Основные команды

| Ввод | Что делает |
|------|-----------|
| `помоги отрефакторить этот файл` | Чат с агентом по умолчанию (coder) |
| `@reviewer проверь эту функцию` | Обращение к конкретному агенту |
| `/help` | Показать доступные команды |
| `/agents` | Список доступных агентов |
| `/model claude-sonnet-4-5-20250514` | Сменить LLM-модель |
| `/config` | Показать текущую конфигурацию |
| `/config set model <имя>` | Сменить модель в реальном времени |
| `/config set streaming on\|off` | Включить/выключить стриминг |
| `/config set show_tool_calls on\|off` | Показывать/скрывать вызовы инструментов |
| `/memory list` | Показать сохранённые воспоминания |
| `/exit` | Выход |

### Клавиши управления

| Клавиша | Действие |
|---------|----------|
| **Enter** | Отправить сообщение |
| **Escape, затем Enter** | Вставить перенос строки |
| **Ctrl+J** | Отправить сообщение (альтернатива) |
| **Tab** | Автодополнение `/`-команд (с описаниями) |

### Статус-бар сессии

Перед каждым приглашением ввода отображается строка состояния:

```
── claude-sonnet-4-6  |  agent: auto  |  turn: 3  |  session: 3.4k tok · $0.012 ──
```

Показывает активную модель, текущего агента, номер хода и суммарные токены с затратами за всю сессию.

### Заголовок ответа ассистента

Каждый ответ ассистента начинается со стилизованного заголовка с именем агента:

```
─────────────── [coder] ───────────────
```

## Первый запуск (режим сервера)

Для использования LIDCO с Android Studio или другими IDE запустите HTTP-сервер:

```bash
lidco serve
```

Сервер запускается на `http://127.0.0.1:8321`. Проверьте:

```bash
curl http://127.0.0.1:8321/api/status
```

Ответ:

```json
{
  "version": "0.1.0",
  "status": "running",
  "model": "gpt-4o-mini",
  "agents": ["architect", "coder", "debugger", "docs", "planner", "refactor", "reviewer", "tester"],
  "memory_entries": 0,
  "project_dir": "/path/to/your/project"
}
```

## Дальнейшие шаги

- [Руководство по HTTP-серверу](./server.md) — настройка и параметры запуска
- [Плагин для Android Studio](./android-studio-plugin.md) — установка плагина IDE
- [Конфигурация](./configuration.md) — настройка моделей, агентов, разрешений
- [Агенты](./agents.md) — создание пользовательских агентов через YAML
